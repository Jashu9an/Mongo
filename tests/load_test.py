#!/usr/bin/env python3
"""
–ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ClickHouse e-commerce –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö vs –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
"""

import clickhouse_connect
import time
import statistics
import concurrent.futures
import json
from datetime import datetime

class ClickHousePerformanceTest:
    def __init__(self, host='localhost', port=8123, user='default', password=''):
        self.client = clickhouse_connect.get_client(host=host, port=port, user=user, password=password)
        self.results = {}
    
    def execute_query(self, query, description):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å –∑–∞–º–µ—Ä–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        start_time = time.time()
        result = self.client.query(query).result_rows
        end_time = time.time()
        
        execution_time = end_time - start_time
        row_count = len(result)
        
        return {
            'time': execution_time,
            'rows': row_count,
            'description': description
        }
    
    def benchmark_query(self, query, description, iterations=10):
        """–ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–ø—Ä–æ—Å–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏"""
        times = []
        
        for i in range(iterations):
            result = self.execute_query(query, f"{description} - –∏—Ç–µ—Ä–∞—Ü–∏—è {i+1}")
            times.append(result['time'])
        
        avg_time = statistics.mean(times)
        min_time = min(times)
        max_time = max(times)
        std_dev = statistics.stdev(times) if len(times) > 1 else 0
        
        return {
            'avg_time': avg_time,
            'min_time': min_time,
            'max_time': max_time,
            'std_dev': std_dev,
            'iterations': iterations,
            'description': description
        }
    
    def test_basic_queries(self):
        """–¢–µ—Å—Ç –±–∞–∑–æ–≤—ã—Ö –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤...")
        
        queries = [
            {
                'name': 'COUNT –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤',
                'raw': "SELECT COUNT(*) FROM ecommerce.ecom_offers",
                'mv': None  # –≠—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å –∏–º–µ–µ—Ç —Å–º—ã—Å–ª —Ç–æ–ª—å–∫–æ –¥–ª—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            },
            {
                'name': 'COUNT –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (TOP 10)',
                'raw': "SELECT category_id, COUNT(*) as cnt FROM ecommerce.ecom_offers GROUP BY category_id ORDER BY cnt DESC LIMIT 10",
                'mv': "SELECT category_id, SUM(products_count) as cnt FROM ecommerce.catalog_by_category_mv GROUP BY category_id ORDER BY cnt DESC LIMIT 10"
            },
            {
                'name': '–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏',
                'raw': "SELECT category_id, COUNT(*), AVG(price), MIN(price), MAX(price) FROM ecommerce.ecom_offers WHERE category_id = 7508",
                'mv': "SELECT category_id, SUM(total_price)/SUM(products_count) as avg_price, min_price, max_price FROM ecommerce.catalog_by_category_mv WHERE category_id = 7508 GROUP BY category_id"
            },
            {
                'name': '–¢–æ–ø –±—Ä–µ–Ω–¥–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏',
                'raw': "SELECT vendor, COUNT(*) FROM ecommerce.ecom_offers WHERE category_id = 7508 AND vendor != '' AND vendor != 'Unknown' GROUP BY vendor ORDER BY COUNT(*) DESC LIMIT 5",
                'mv': "SELECT vendor, SUM(products_count) FROM ecommerce.catalog_by_brand_mv WHERE category_id = 7508 GROUP BY vendor ORDER BY SUM(products_count) DESC LIMIT 5"
            }
        ]
        
        for query_info in queries:
            print(f"\n--- {query_info['name']} ---")
            
            # –¢–µ—Å—Ç —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if query_info['raw']:
                raw_result = self.benchmark_query(query_info['raw'], f"–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ: {query_info['name']}")
                self.results[f"{query_info['name']}_raw"] = raw_result
                print(f"–°—ã—Ä—ã–µ:   {raw_result['avg_time']:.4f}s (min: {raw_result['min_time']:.4f}s, max: {raw_result['max_time']:.4f}s)")
            
            # –¢–µ—Å—Ç –º–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
            if query_info['mv']:
                mv_result = self.benchmark_query(query_info['mv'], f"–ú–í: {query_info['name']}")
                self.results[f"{query_info['name']}_mv"] = mv_result
                print(f"–ú–í:      {mv_result['avg_time']:.4f}s (min: {mv_result['min_time']:.4f}s, max: {mv_result['max_time']:.4f}s)")
                
                # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                if raw_result and mv_result:
                    speedup = raw_result['avg_time'] / mv_result['avg_time']
                    print(f"–£—Å–∫–æ—Ä–µ–Ω–∏–µ: {speedup:.2f}x")
    
    def test_concurrent_load(self, concurrent_users=10, queries_per_user=5):
        """–¢–µ—Å—Ç –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏"""
        print(f"\n‚ö° –ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {concurrent_users} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, {queries_per_user} –∑–∞–ø—Ä–æ—Å–æ–≤ –∫–∞–∂–¥—ã–π")
        
        queries = [
            "SELECT COUNT(*) FROM ecommerce.ecom_offers",
            "SELECT category_id, COUNT(*) FROM ecommerce.ecom_offers GROUP BY category_id LIMIT 5",
            "SELECT vendor, COUNT(*) FROM ecommerce.ecom_offers WHERE vendor != '' GROUP BY vendor LIMIT 10"
        ]
        
        def user_simulation(user_id):
            """–°–∏–º—É–ª—è—Ü–∏—è —Ä–∞–±–æ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
            user_times = []
            for i in range(queries_per_user):
                query = queries[i % len(queries)]
                start_time = time.time()
                try:
                    rows = self.client.query(query).result_rows
                    execution_time = time.time() - start_time
                    user_times.append(execution_time)
                except Exception as e:
                    print(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id}, –∑–∞–ø—Ä–æ—Å {i}: –æ—à–∏–±–∫–∞ {e}")
                    user_times.append(10.0) # —Ç–∞–π–º–∞—É—Ç –∫–∞–∫ –æ—à–∏–±–∫–∞
            return user_times
        
        # –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = [executor.submit(user_simulation, user_id) for user_id in range(concurrent_users)]
            all_times = []
            
            for future in concurrent.futures.as_completed(futures):
                user_times = future.result()
                all_times.extend(user_times)
        
        if all_times:
            avg_response_time = statistics.mean(all_times)
            max_response_time = max(all_times)
            qps = (concurrent_users * queries_per_user) / sum(all_times)
            
            print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {avg_response_time:.4f}s")
            print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {max_response_time:.4f}s")
            print(f"QPS (–∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫): {qps:.2f}")
            
            return {
                'avg_response_time': avg_response_time,
                'max_response_time': max_response_time,
                'qps': qps,
                'total_queries': len(all_times)
            }
        
        return None
    
    def save_results(self, filename='performance_results.json'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        timestamp = datetime.now().isoformat()
        results_with_timestamp = {
            'timestamp': timestamp,
            'environment': {
                'dataset_size': '3.99M records',
                'materialized_views': 4,
                'clickhouse_version': self.client.query('SELECT version()').first_row[0]
            },
            'benchmarks': self.results
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results_with_timestamp, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")
    
    def generate_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        report = []
        report.append("=" * 60)
        report.append("CLICKHOUSE PERFORMANCE TEST REPORT")
        report.append("=" * 60)
        report.append(f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"–î–∞–Ω–Ω—ã–µ: 3.99M –∑–∞–ø–∏—Å–µ–π ecommerce")
        report.append(f"–ú–∞—Ç–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è: 4")
        report.append("")
        
        # –ê–Ω–∞–ª–∏–∑ —É—Å–∫–æ—Ä–µ–Ω–∏—è
        speedups = []
        for key, result in self.results.items():
            if key.endswith('_raw') and f"{key[:-4]}_mv" in self.results:
                raw_time = result['avg_time']
                mv_time = self.results[f"{key[:-4]}_mv"]['avg_time']
                speedup = raw_time / mv_time
                speedups.append(speedup)
                report.append(f"üìà –£—Å–∫–æ—Ä–µ–Ω–∏–µ {key[:-4]}: {speedup:.2f}x")
        
        if speedups:
            avg_speedup = statistics.mean(speedups)
            report.append("")
            report.append(f"üéØ –°—Ä–µ–¥–Ω–µ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: {avg_speedup:.2f}x")
            report.append(f"üìä –ú–∞–∫—Å–∏–º—É–º —É—Å–∫–æ—Ä–µ–Ω–∏—è: {max(speedups):.2f}x")
            report.append(f"üìâ –ú–∏–Ω–∏–º—É–º —É—Å–∫–æ—Ä–µ–Ω–∏—è: {min(speedups):.2f}x")
        
        report.append("")
        report.append("–î–ï–¢–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        for key, result in self.results.items():
            query_type = "–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ" if key.endswith('_raw') else "–ú–í"
            report.append(f"{query_type}: {result['description']}")
            report.append(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è: {result['avg_time']:.4f}s")
            report.append(f"  –ú–∏–Ω–∏–º—É–º: {result['min_time']:.4f}s")
            report.append(f"  –ú–∞–∫—Å–∏–º—É–º: {result['max_time']:.4f}s")
            report.append("")
        
        return "\n".join(report)

def main():
    print("üöÄ –ó–∞–ø—É—Å–∫ –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ClickHouse")
    print("=" * 50)
    
    test = ClickHousePerformanceTest()
    
    try:
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        test.test_basic_queries()
        
        # –ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        concurrent_results = test.test_concurrent_load(concurrent_users=5, queries_per_user=3)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        test.save_results('C:/VSCode projects/Databases/clickhouse-mongo-subd/performance_results.json')
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        report = test.generate_report()
        print("\n" + report)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –≤ —Ñ–∞–π–ª
        with open('C:/VSCode projects/Databases/clickhouse-mongo-subd/performance_report.txt', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ performance_report.txt")
        print(f"üìä –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ performance_results.json")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
