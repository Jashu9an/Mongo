#!/usr/bin/env python3
"""
–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ClickHouse
"""

import clickhouse_connect
import time
import statistics
import concurrent.futures
import json
from datetime import datetime

def test_performance():
    client = clickhouse_connect.get_client(host='localhost', port=8123, user='default', password='')
    
    print("üöÄ –ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ClickHouse e-commerce")
    print("=" * 50)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    queries = [
        {
            'name': 'COUNT –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤',
            'raw_query': "SELECT COUNT(*) FROM ecommerce.ecom_offers",
            'mv_query': None
        },
        {
            'name': 'COUNT –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (TOP 10)',
            'raw_query': "SELECT category_id, COUNT(*) as cnt FROM ecommerce.ecom_offers GROUP BY category_id ORDER BY cnt DESC LIMIT 10",
            'mv_query': "SELECT category_id, SUM(products_count) as cnt FROM ecommerce.catalog_by_category_mv GROUP BY category_id ORDER BY cnt DESC LIMIT 10"
        },
        {
            'name': '–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏',
            'raw_query': "SELECT COUNT(*), AVG(price), MIN(price), MAX(price) FROM ecommerce.ecom_offers WHERE category_id = 7508",
            'mv_query': "SELECT SUM(total_price)/SUM(products_count) as avg_price, min_price, max_price FROM ecommerce.catalog_by_category_mv WHERE category_id = 7508"
        },
        {
            'name': '–¢–æ–ø –±—Ä–µ–Ω–¥–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏',
            'raw_query': "SELECT vendor, COUNT(*) FROM ecommerce.ecom_offers WHERE category_id = 7508 AND vendor != '' AND vendor != 'Unknown' GROUP BY vendor ORDER BY COUNT(*) DESC LIMIT 5",
            'mv_query': "SELECT vendor, SUM(products_count) FROM ecommerce.catalog_by_brand_mv WHERE category_id = 7508 GROUP BY vendor ORDER BY SUM(products_count) DESC LIMIT 5"
        }
    ]
    
    results = {}
    
    for test_query in queries:
        print(f"\nüìä {test_query['name']}")
        print("-" * 40)
        
        # –¢–µ—Å—Ç —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if test_query['raw_query']:
            raw_times = []
            for i in range(5):
                start = time.time()
                try:
                    rows = client.query(test_query['raw_query']).result_rows
                    execution_time = time.time() - start
                    raw_times.append(execution_time)
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
                    break
            
            if raw_times:
                avg_raw = statistics.mean(raw_times)
                min_raw = min(raw_times)
                max_raw = max(raw_times)
                print(f"–°—ã—Ä—ã–µ:   {avg_raw:.4f}s (min: {min_raw:.4f}s, max: {max_raw:.4f}s)")
                results[f"{test_query['name']}_raw"] = {'avg': avg_raw, 'min': min_raw, 'max': max_raw}
        
        # –¢–µ—Å—Ç –ú–í
        if test_query['mv_query']:
            try:
                mv_times = []
                for i in range(5):
                    start = time.time()
                    rows = client.query(test_query['mv_query']).result_rows
                    execution_time = time.time() - start
                    mv_times.append(execution_time)
                
                avg_mv = statistics.mean(mv_times)
                min_mv = min(mv_times)
                max_mv = max(mv_times)
                print(f"–ú–í:      {avg_mv:.4f}s (min: {min_mv:.4f}s, max: {max_mv:.4f}s)")
                results[f"{test_query['name']}_mv"] = {'avg': avg_mv, 'min': min_mv, 'max': max_mv}
                
                # —Ä–∞—Å—á–µ—Ç —É—Å–∫–æ—Ä–µ–Ω–∏—è
                if raw_times:
                    speedup = avg_raw / avg_mv
                    print(f"üöÄ –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {speedup:.2f}x")
                    results[f"{test_query['name']}_speedup"] = speedup
                    
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ú–í: {e}")
    
    # –ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print(f"\n‚ö° –ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...")
    concurrent_queries = [
        "SELECT COUNT(*) FROM ecommerce.ecom_offers",
        "SELECT category_id, COUNT(*) FROM ecommerce.ecom_offers GROUP BY category_id LIMIT 5",
        "SELECT vendor, COUNT(*) FROM ecommerce.ecom_offers WHERE vendor != '' GROUP BY vendor LIMIT 10"
    ]
    
    def run_query(query):
        start = time.time()
        try:
            client.query(query)
            return time.time() - start
        except:
            return 10.0  # –æ—à–∏–±–∫–∞/—Ç–∞–π–º–∞—É—Ç
    
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
    total_times = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(run_query, q) for q in concurrent_queries for _ in range(3)]
        
        for future in concurrent.futures.as_completed(futures):
            execution_time = future.result()
            total_times.append(execution_time)
    
    if total_times:
        avg_response = statistics.mean(total_times)
        max_response = max(total_times)
        total_queries = len(total_times)
        total_time = sum(total_times)
        qps = total_queries / total_time
        
        print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {avg_response:.4f}s")
        print(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è: {max_response:.4f}s") 
        print(f"QPS: {qps:.2f}")
        
        results['load_test'] = {
            'avg_response': avg_response,
            'max_response': max_response,
            'total_queries': total_queries,
            'qps': qps
        }
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results['timestamp'] = datetime.now().isoformat()
    results['dataset_size'] = '3.99M records'
    
    with open('/Users/matyushov.iv/Desktop/lab-clickhouse/performance_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
    print(f"\nüìä –ò–¢–û–ì–ò –ù–ê–ì–†–£–ó–û–ß–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 50)
    
    speedups = []
    for key, value in results.items():
        if key.endswith('_speedup'):
            speedups.append(value)
            query_name = key.replace('_speedup', '')
            print(f"üöÄ {query_name}: {value:.2f}x —É—Å–∫–æ—Ä–µ–Ω–∏–µ")
    
    if speedups:
        avg_speedup = statistics.mean(speedups)
        print(f"\nüéØ –°—Ä–µ–¥–Ω–µ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: {avg_speedup:.2f}x")
        print(f"üìä –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: {max(speedups):.2f}x")
        print(f"üìâ –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É—Å–∫–æ—Ä–µ–Ω–∏–µ: {min(speedups):.2f}x")
    
    if 'load_test' in results:
        load = results['load_test']
        print(f"\n‚ö° –ù–∞–≥—Ä—É–∑–æ—á–Ω—ã–π —Ç–µ—Å—Ç: {load['total_queries']} –∑–∞–ø—Ä–æ—Å–æ–≤")
        print(f"üìà QPS: {load['qps']:.2f} –∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫")
        print(f"‚è±Ô∏è  –°—Ä–µ–¥–Ω–∏–π –æ—Ç–≤–µ—Ç: {load['avg_response']:.4f}s")
    
    return results

if __name__ == '__main__':
    try:
        test_performance()
        print(f"\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìÑ –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ performance_results.json")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
